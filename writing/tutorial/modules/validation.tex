% ======================================================================
\section{SBI Validation Pipeline}
% ======================================================================
% ----------------------------------------------------------------------
\begin{frame}{SBI Validation Pipeline}
	\begin{itemize}
		\item Construct distance matrix and local statistics.
		\item Preprocessing I: Outlier removal.
		\item Assess coverage and fidelity.
		\item Preprocessing II: Uniform resampling.
		\item Construct the Laplacian and recompute local statistics.
		\item Estimate intrinsic dimension.
		\item Manifold Learning: \diffmap.
		\item Manifold Interpretation \& Visualization I: \ies and plotting.
		\item Manifold Interpretation \& Visualization II: \tslasso.
		\item Manifold Interpretation \& Visualization III: \rrelex.
	\end{itemize}
\end{frame}

% ----------------------------------------------------------------------
% 1. Construct distance matrix and local statistics
% ----------------------------------------------------------------------
\begin{frame}{Construct Distance Matrix and Local Statistics}
	
	\textbf{Optional Step: Sub-sampling for tractability}
	\begin{itemize}
		\item Many downstream operations scale superlinearly in $N$:
		\begin{itemize}
			\item pairwise distances / neighbor graphs,
			\item spectral decompositions of graph Laplacians,
			\item local statistics (kNN, radius counts, etc.),
			\item local covariance matrices and their spectral decompositions. 
		\end{itemize}
		\item If $N$ is very large:
		\begin{itemize}
			\item Randomly sub-sample to a size that:
			\begin{itemize}
				\item still captures the geometry of the data,
				\item fits within the available computational budget.
			\end{itemize}
			\item In general, one should use as many points as resources allow.
		\end{itemize}
	\end{itemize}
	
\end{frame}

\begin{frame}{Construct Distance Matrix and Local Statistics}
	
	\textbf{Main Step: Distance matrix and local statistics}
	\begin{itemize}
		\item Compute distances between latent points in $\X$.
		\item For each point $x \in \X$, compute local statistics:
		\begin{itemize}
			\item $\dk[x]$: distance to the $k$-th nearest neighbor for a range $k \in \{k_{\min}, \dots, k_{\max}\}$ or,
			\item $\nr[x]$: the number of neighbors within radius $r$ for a range $r \in \{r_{\min}, \dots, r_{\max}\}$.
		\end{itemize}
	\end{itemize}
	
	\textbf{Practical notes:}
	\begin{itemize}
		\item Store distances in sparse form.
		\item As we subsample the data, slice the already computed distance matrix.
		\item Reuse the same local statistics across multiple steps in the pipeline.
	\end{itemize}
\end{frame}


% ----------------------------------------------------------------------
% 2. Preprocessing I: Outlier removal
% ----------------------------------------------------------------------

\begin{frame}{Preprocessing I: Outlier Removal}
	\textbf{Motivation}
	\begin{itemize}
		\item Highly noisy or pathological points:
		\begin{itemize}
			\item are not representative of the underlying geometry or data distribution
			\item distort local geometry,
			\item destabilize spectral embeddings,
			\item bias intrinsic dimension estimates.
		\end{itemize}
		\item For this purpose, we want a \textbf{clean}(i.e. outlier free) subset $\X^{clean} \subseteq \X$.
	\end{itemize}
	\vspace{0.7em}
	\textbf{Recommended approach: Minimum Volume Sets (MVS)}
\end{frame}